{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd() #get working directory\n",
    "\n",
    "pd_file_names = [] #empty array for filenames\n",
    "tms_file_names = [] \n",
    "pa_file_names = []\n",
    "\n",
    "#append all file names within folders into list\n",
    "for (dirpath, dirnames, filenames) in os.walk(path + '/player_data/'):\n",
    "    pd_file_names.extend(filenames)\n",
    "    break\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path + '/team_misc_data/'):\n",
    "    tms_file_names.extend(filenames)\n",
    "    break\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk(path + '/player_advanced_data/'):\n",
    "    pa_file_names.extend(filenames)\n",
    "    break\n",
    "    \n",
    "#drop '.DS_Store'\n",
    "pd_file_names.remove('.DS_Store')\n",
    "tms_file_names.remove('.DS_Store')\n",
    "pa_file_names.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd_list = [] #empty list for data storage\n",
    "tms_list = []\n",
    "pa_list = []\n",
    "\n",
    "#read in player data\n",
    "for i in pd_file_names:\n",
    "    data = pd.read_csv(path + '/player_data/' + i, sep=',', quoting=3)\n",
    "    pd_list.append(data)\n",
    "#read in team data\n",
    "for i in tms_file_names:\n",
    "    data = pd.read_csv(path + '/team_misc_data/' + i, sep=',', quoting=3)\n",
    "    tms_list.append(data)\n",
    "#read in player advanced data\n",
    "for i in pa_file_names:\n",
    "    data = pd.read_csv(path + '/player_advanced_data/' + i, sep=',', quoting=3)\n",
    "    pa_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create list of seasons to append to each data set within list\n",
    "season_list = [2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011,\n",
    "              2012, 2013, 2014, 2015, 2016, 2017]\n",
    "\n",
    "#empty lists\n",
    "pd_list_new = []\n",
    "tms_list_new = []\n",
    "pa_list_new = []\n",
    "\n",
    "#for each data set & season\n",
    "for h,i,j,k in zip(pa_list, pd_list, tms_list, season_list):\n",
    "    #create data frame with season repeating the same length as player/team data\n",
    "    season_pa = pd.DataFrame(np.repeat(k, len(h)))\n",
    "    season_pd = pd.DataFrame(np.repeat(k, len(i)))\n",
    "    season_tms = pd.DataFrame(np.repeat(k, len(j)))\n",
    "    #name column\n",
    "    season_pd.columns = ['season']; season_tms.columns = ['season']\n",
    "    #concatentate column and return data to list\n",
    "    data_pa = pd.concat([h, season_pa], axis=1)\n",
    "    data_pd = pd.concat([i, season_pd], axis=1)\n",
    "    data_tms = pd.concat([j, season_tms], axis=1)\n",
    "    pa_list_new.append(data_pa)\n",
    "    pd_list_new.append(data_pd)\n",
    "    tms_list_new.append(data_tms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Player data cleaning\n",
    "pd_data = pd.concat(pd_list_new, axis=0) #concatenate all data into single data set\n",
    "\n",
    "#Check which colums have too many NA values\n",
    "pd_data.isnull().sum()\n",
    "\n",
    "#Based on manual analysis (to understand the data)..\n",
    "drop_columns = ['\"Rk']\n",
    "\n",
    "#Drop the columns\n",
    "pd_data = pd_data.drop(pd_data.loc[:,drop_columns].columns, axis=1)\n",
    "\n",
    "#Rename column + remove quote from values + convert to float\n",
    "pd_data.rename(columns={'PS/G\"': 'pts'}, inplace=True)\n",
    "pd_data['pts'] = pd_data['pts'].str.replace('\"', \"\")\n",
    "pd_data['pts'] = pd_data['pts'].astype(float)\n",
    "\n",
    "#remove player code from player name\n",
    "players = pd_data['Player'].str.partition(\"\\\\\")[0]\n",
    "pd_data['Player'] = players\n",
    "\n",
    "#lower the column names\n",
    "pd_columns = pd_data.columns.str.lower()\n",
    "pd_data.columns = pd_columns\n",
    "\n",
    "#reset index\n",
    "pd_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Player advanced data cleansing\n",
    "pa_data = pd.concat(pa_list_new, axis=0) #concatenate all data into single data set\n",
    "\n",
    "#Check which colums have too many NA values\n",
    "pa_data.isnull().sum()\n",
    "\n",
    "#Based on manual analysis (to understand the data)..\n",
    "drop_columns = ['\"Rk', 'Pos', 'Age', 'G', 'MP', 'Unnamed: 19', 'Unnamed: 24']\n",
    "\n",
    "#Drop the columns\n",
    "pa_data = pa_data.drop(pa_data.loc[:,drop_columns].columns, axis=1)\n",
    "\n",
    "#Rename column + remove quote from values + convert to float\n",
    "pa_data.rename(columns={'VORP\"': 'vorp', 0: 'season'}, inplace=True)\n",
    "pa_data['vorp'] = pa_data['vorp'].str.replace('\"', \"\")\n",
    "pa_data['vorp'] = pa_data['vorp'].astype(float)\n",
    "\n",
    "#remove player code from player name\n",
    "players = pa_data['Player'].str.partition(\"\\\\\")[0]\n",
    "pa_data['Player'] = players\n",
    "\n",
    "#lower the column names\n",
    "pa_columns = pa_data.columns.str.lower()\n",
    "pa_data.columns = pa_columns\n",
    "\n",
    "#reset index\n",
    "pa_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Team data cleansing\n",
    "tms_data = pd.concat(tms_list_new, axis=0) #concatenate all data into single data set\n",
    "\n",
    "#Which columns to remove based on the statistic definition?\n",
    "# remove pythagorean wins/losses, will be hard to reproduce within player stats\n",
    "# remove margin of victory, can't repro with plaer stats\n",
    "# remove sos, not applicable\n",
    "# remove srs, not applicable\n",
    "# remove pace, not going to able to reproduce\n",
    "# remove arena & attendance\n",
    "drop_columns= ['\"Rk', 'PW', 'PL', 'MOV', 'SOS', 'SRS', 'Pace', 'Arena', 'Attendance\"']\n",
    "\n",
    "#Drop the columns\n",
    "tms_data = tms_data.drop(tms_data.loc[:,drop_columns].columns, axis=1)\n",
    "\n",
    "#Rename the redundant columns related to defensive efficiency\n",
    "tms_data.rename(columns={'eFG%.1':'eFG%_def', 'TOV%.1':'TOV%_def', 'FT/FGA.1': 'FT/FGA_def'}, inplace=True)\n",
    "\n",
    "#lower the column names\n",
    "tms_columns = tms_data.columns.str.lower()\n",
    "tms_data.columns = tms_columns\n",
    "\n",
    "#Remove season averages from data, found via exploratory analysis\n",
    "season_average_data = tms_data[tms_data.isnull().any(axis=1)] #extract season averages\n",
    "tms_data = tms_data[-tms_data.isnull().any(axis=1)] #remove from tms_data\n",
    "\n",
    "#Handle asterix indicating playoffs within team name\n",
    "partition = tms_data['team'].str.partition(\"*\")\n",
    "partition[1].replace([\"*\", \"\"], [\"map\", \"mip\"], inplace=True) #{map: made playofs, mip: missed playoffs}\n",
    "\n",
    "playoff_data = partition.loc[:,0:1] #create new data about whether team made playoffs\n",
    "playoff_data = pd.concat([playoff_data, tms_data['season']], axis=1) #add season for merge purpose\n",
    "playoff_data.rename(columns={'0':'team', '1':'playoff_status'}, inplace=True) #clean columns\n",
    "\n",
    "tms_data['team'] = partition[0] #return cleaned names to tms data\n",
    "\n",
    "#adding winnig percentage to tms_data\n",
    "tms_data['wp'] = tms_data['w'] / (tms_data['l'] + tms_data['w'])\n",
    "\n",
    "#reset index\n",
    "tms_data.reset_index(drop=True, inplace=True)\n",
    "season_average_data.reset_index(drop=True, inplace=True)\n",
    "playoff_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Clean & handle the discrepencies in team names across data sets\n",
    "tms_data['team'].unique() #reviewed team names\n",
    "pd_data['tm'].unique() #review abbreviations\n",
    "pa_data['tm'].unique()\n",
    "\n",
    "#Drop pd_data with 'TOT' abbreviation - indicates player was on multiple teams\n",
    "pd_data = pd_data.loc[pd_data['tm'] != 'TOT']\n",
    "pa_data = pa_data.loc[pa_data['tm'] != 'TOT']\n",
    "#Remove tms_data for New Orleans/OKH - no matching abbreviation ... NEED TO DO TO PLAYOFFS DATA\n",
    "tms_data = tms_data.loc[tms_data['team'] != 'New Orleans/Oklahoma City Hornets']\n",
    "\n",
    "#import abbreviation data built from seeing unique values between data sets\n",
    "team_abbr_map = pd.read_csv(path + '/team_abbr_mapping.csv')\n",
    "team_abbr_map.columns = ['team_acronym', 'team_name']\n",
    "\n",
    "#merge standardized team name / abbreviation into data sets\n",
    "pd_data = pd_data.merge(team_abbr_map, left_on = 'tm', right_on = 'team_acronym', how='left')\n",
    "pa_data = pa_data.merge(team_abbr_map, left_on = 'tm', right_on = 'team_acronym', how='left')\n",
    "\n",
    "pd_data['team_acronym'] = pd_data['team_acronym'].str.lower()\n",
    "pa_data['team_acronym'] = pa_data['team_acronym'].str.lower()\n",
    "\n",
    "pd_data['team_name'] = pd_data['team_name'].str.lower()\n",
    "pa_data['team_name'] = pa_data['team_name'].str.lower()\n",
    "\n",
    "pd_data['team_name'] = pd_data['team_name'].str.replace(\" \", \"_\")\n",
    "pa_data['team_name'] = pa_data['team_name'].str.replace(\" \", \"_\")\n",
    "\n",
    "del pd_data['tm'] \n",
    "del pa_data['tm']\n",
    "#del pd_data['index']\n",
    "#del pa_data['index']\n",
    "\n",
    "#team data is already consistent with team names\n",
    "tms_data.rename(columns={'team': 'team_name'}, inplace=True)\n",
    "tms_data['team_name'] = tms_data['team_name'].str.lower()\n",
    "tms_data['team_name'] = tms_data['team_name'].str.replace(\" \", \"_\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge the player data together\n",
    "pd_pa_data = pd_data.merge(pa_data, on=['player', 'team_name', 'season'], how='left')\n",
    "pd_pa_data.columns\n",
    "\n",
    "#Drop columns\n",
    "pd_pa_data = pd_pa_data.drop('team_acronym_y', axis=1)\n",
    "pd_pa_data.rename(columns={'team_acronym_x':'team_acronym'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Next steps:\n",
    "# 1.create function that will aggregate team stats by the players input...\n",
    "# 2. then use this function to aggregate the player stats per team per year for each season...\n",
    "# 3. and use this data set to train the model against wins\n",
    "\n",
    "# 1.create function that will aggregate team stats by the players input...\n",
    "def aggregatePlayerStats(data, player_list):\n",
    "    team_data = data[data['player'].isin(player_list)] #subset data in the player list\n",
    "    sum_data = team_data[['fg', 'fga', '3p', '3pa', '2p', '2pa', 'ft', 'fta',\n",
    "                       'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'mp']].sum()\n",
    "    avg_data = team_data[['2p%', '3p%', 'fg%', 'ft%', 'efg%', 'age']].mean()\n",
    "    final = pd.DataFrame(pd.concat([sum_data, avg_data], axis=0)).transpose()\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.create function that will aggregate team stats by the players input...\n",
    "# 2. then use this function to aggregate the player stats per team per year for each season...\n",
    "# 3. and use this data set to train the model against wins\n",
    "\n",
    "# 1.create function that will aggregate team stats by the players input...\n",
    "def aggregatePlayerStatsAdvanced(data, player_list):\n",
    "    team_data = data[data['player'].isin(player_list)] #subset data in the player list\n",
    "    sum_data = team_data[['fg', 'fga', '3p', '3pa', '2p', '2pa', 'ft', 'fta',\n",
    "                       'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'mp']].sum()\n",
    "    avg_data = team_data[['2p%', '3p%', 'fg%', 'ft%', 'efg%', 'age', 'per', '3par',\n",
    "                         'ftr', 'orb%', 'drb%', 'trb%', 'ast%', 'stl%', 'blk%', 'tov%',\n",
    "                         'usg%', 'ows', 'dws', 'ws', 'ws/48', 'obpm', 'dbpm', 'bpm', 'vorp']].mean()\n",
    "    final = pd.DataFrame(pd.concat([sum_data, avg_data], axis=0)).transpose()\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. then use this function to aggregate the player stats per team per year for each season...\n",
    "historical_team_data = []\n",
    "import itertools\n",
    "for i, j in itertools.product(pd_data['team_name'].unique(), pd_data['season'].unique()):\n",
    "    #subset player data\n",
    "    team_year_data = pd_data.loc[(pd_data.team_name == i) & (pd_data.season == j)]    \n",
    "    #aggreagete team stats \n",
    "    agg_stats = aggregatePlayerStats(team_year_data, team_year_data['player'].unique())\n",
    "    #include win losses for the team that year\n",
    "    agg_stats = pd.concat([pd.DataFrame(tms_data.loc[(tms_data.team_name == i) & \n",
    "                    (tms_data.season == j), ['w', 'l', 'wp']]).reset_index(drop=True),\n",
    "                       agg_stats], axis=1)\n",
    "    final = pd.concat([pd.DataFrame({'team_name': [i], 'season': [j]}), agg_stats], axis=1)\n",
    "    historical_team_data.append(final)  \n",
    "                      \n",
    "historical_team_data = pd.concat(historical_team_data, axis=0) #concatenate all data into single data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. then use this function to aggregate the player stats per team per year for each season...\n",
    "historical_team_data_top_5 = []\n",
    "import itertools\n",
    "#for each combination of team & season\n",
    "for i, j in itertools.product(pd_data['team_name'].unique(), pd_data['season'].unique()):\n",
    "    #subset player data\n",
    "    team_year_data = pd_data.loc[(pd_data.team_name == i) & (pd_data.season == j)]\n",
    "    #identify top 5 players by minutes played\n",
    "    team_year_data_top_5 = team_year_data.sort_values(by='mp', axis=0, ascending=False)[0:4]\n",
    "    #aggregate team stats\n",
    "    agg_stats = aggregatePlayerStats(team_year_data, team_year_data_top_5['player'].unique())\n",
    "    #include win losses for the team that year\n",
    "    agg_stats = pd.concat([pd.DataFrame(tms_data.loc[(tms_data.team_name == i) & \n",
    "                    (tms_data.season == j), ['w', 'l', 'wp']]).reset_index(drop=True),\n",
    "                       agg_stats], axis=1)\n",
    "    #combine all stats\n",
    "    final = pd.concat([pd.DataFrame({'team_name': [i], 'season': [j]}), agg_stats], axis=1)\n",
    "    historical_team_data_top_5.append(final)\n",
    "                      \n",
    "historical_team_data_top_5 = pd.concat(historical_team_data_top_5, axis=0) #concatenate all data into single data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this will be top 5 based on the # of games started... generally this is the squad\n",
    "historical_team_data_top_5_gs = []\n",
    "import itertools\n",
    "#for each combination of team & season\n",
    "for i, j in itertools.product(pd_data['team_name'].unique(), pd_data['season'].unique()):\n",
    "    #subset player data\n",
    "    team_year_data = pd_data.loc[(pd_data.team_name == i) & (pd_data.season == j)]\n",
    "    #identify top 5 players by minutes played\n",
    "    team_year_data_top_5 = team_year_data.sort_values(by='gs', axis=0, ascending=False)[0:4]\n",
    "    #aggregate team stats\n",
    "    agg_stats = aggregatePlayerStats(team_year_data, team_year_data_top_5['player'].unique())\n",
    "    #include win losses for the team that year\n",
    "    agg_stats = pd.concat([pd.DataFrame(tms_data.loc[(tms_data.team_name == i) & \n",
    "                    (tms_data.season == j), ['w', 'l', 'wp']]).reset_index(drop=True),\n",
    "                       agg_stats], axis=1)\n",
    "    #combine all stats\n",
    "    final = pd.concat([pd.DataFrame({'team_name': [i], 'season': [j]}), agg_stats], axis=1)\n",
    "    historical_team_data_top_5_gs.append(final)\n",
    "                      \n",
    "historical_team_data_top_5_gs = pd.concat(historical_team_data_top_5_gs, axis=0) #concatenate all data into single data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. then use this function to aggregate the player stats per team per year for each season...\n",
    "historical_team_data_top_5_advanced = []\n",
    "import itertools\n",
    "#for each combination of team & season\n",
    "for i, j in itertools.product(pd_pa_data['team_name'].unique(), pd_pa_data['season'].unique()):\n",
    "    #subset player data\n",
    "    team_year_data = pd_pa_data.loc[(pd_pa_data.team_name == i) & (pd_pa_data.season == j)]\n",
    "    #identify top 5 players by minutes played\n",
    "    team_year_data_top_5 = team_year_data.sort_values(by='mp', axis=0, ascending=False)[0:4]\n",
    "    #aggregate team stats\n",
    "    agg_stats = aggregatePlayerStatsAdvanced(team_year_data, team_year_data_top_5['player'].unique())\n",
    "    #include win losses for the team that year\n",
    "    agg_stats = pd.concat([pd.DataFrame(tms_data.loc[(tms_data.team_name == i) & \n",
    "                    (tms_data.season == j), ['w', 'l', 'wp']]).reset_index(drop=True),\n",
    "                       agg_stats], axis=1)\n",
    "    #combine all stats\n",
    "    final = pd.concat([pd.DataFrame({'team_name': [i], 'season': [j]}), agg_stats], axis=1)\n",
    "    historical_team_data_top_5_advanced.append(final)\n",
    "                      \n",
    "historical_team_data_top_5_advanced = pd.concat(historical_team_data_top_5_advanced, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove records without wins data, team didn't exist\n",
    "#something wrong with 2015 data, will investigate at another time\n",
    "historical_team_data = historical_team_data.loc[(historical_team_data['w'].notnull())]\n",
    "historical_team_data_top_5 = historical_team_data_top_5.loc[(historical_team_data_top_5['w'].notnull())]\n",
    "historical_team_data_top_5_gs = historical_team_data_top_5_gs.loc[(historical_team_data_top_5_gs['w'].notnull())]\n",
    "historical_team_data_top_5_advanced = historical_team_data_top_5_advanced.loc[(\n",
    "    historical_team_data_top_5_advanced['w'].notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a historical player data set that only includes 1 record per player per season, based on games played on team\n",
    "player_data_sr = pd.DataFrame()\n",
    "for i in pd_data['season'].unique():\n",
    "    season_data = pd_data[pd_data['season']==i]\n",
    "    season_data_sr = season_data.sort_values('g', ascending=False).groupby('player', as_index=False).first()\n",
    "    player_data_sr = player_data_sr.append(season_data_sr)\n",
    "    \n",
    "#create a historical player data set that only includes 1 record per player per season, based on games played on team\n",
    "player_data_sr_advanced = pd.DataFrame()\n",
    "for i in pd_pa_data['season'].unique():\n",
    "    season_data = pd_pa_data[pd_pa_data['season']==i]\n",
    "    season_data_sr = season_data.sort_values('g', ascending=False).groupby('player', as_index=False).first()\n",
    "    player_data_sr_advanced = player_data_sr_advanced.append(season_data_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##get the average stats per team for top 5 players\n",
    "\n",
    "team_data = historical_team_data_top_5\n",
    "#relevant data for z scores are...\n",
    "team_data.columns #fg%, fga, 3p%, 3pa, 2pa, 2p%, fta, ft%, ord, drb, trb, ast, stl, blk, tov, pf, pts, efg%\n",
    "#removing age because it directionality of stat is unclear (older versus younger... probably middle is better)\n",
    "team_data = team_data[['season','fg%', 'fga', '3p%', '3pa', '2p%', '2pa', 'ft%', 'fta', 'orb', 'drb', 'trb', 'ast', 'stl',\n",
    "                      'blk', 'tov', 'pf', 'pts', 'efg%', 'age']]\n",
    "average_stats = pd.DataFrame()\n",
    "seasons = team_data['season'].unique()\n",
    "\n",
    "temp_data = team_data.drop('season', axis=1)\n",
    "for s in seasons:\n",
    "    season_data = temp_data[team_data['season'] == s]\n",
    "    season_statistics_top_5 = pd.DataFrame(columns = ['mean', 'sd'])\n",
    "    season_statistics_top_5['mean'] = season_data.mean()\n",
    "    season_statistics_top_5['sd'] = season_data.std()\n",
    "    season_statistics_top_5 = season_statistics_top_5.transpose()\n",
    "    season_statistics_top_5['season'] = s\n",
    "    average_stats = average_stats.append(season_statistics_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##get the average stats per team for top 5 players based on the number of agmes started \n",
    "\n",
    "team_data = historical_team_data_top_5_gs\n",
    "#relevant data for z scores are...\n",
    "team_data.columns #fg%, fga, 3p%, 3pa, 2pa, 2p%, fta, ft%, ord, drb, trb, ast, stl, blk, tov, pf, pts, efg%\n",
    "#removing age because it directionality of stat is unclear (older versus younger... probably middle is better)\n",
    "team_data = team_data[['season','fg%', 'fga', '3p%', '3pa', '2p%', '2pa', 'ft%', 'fta', 'orb', 'drb', 'trb', 'ast', 'stl',\n",
    "                      'blk', 'tov', 'pf', 'pts', 'efg%', 'age']]\n",
    "average_stats_gs = pd.DataFrame()\n",
    "seasons = team_data['season'].unique()\n",
    "\n",
    "temp_data = team_data.drop('season', axis=1)\n",
    "for s in seasons:\n",
    "    season_data = temp_data[team_data['season'] == s]\n",
    "    season_statistics_top_5 = pd.DataFrame(columns = ['mean', 'sd'])\n",
    "    season_statistics_top_5['mean'] = season_data.mean()\n",
    "    season_statistics_top_5['sd'] = season_data.std()\n",
    "    season_statistics_top_5 = season_statistics_top_5.transpose()\n",
    "    season_statistics_top_5['season'] = s\n",
    "    average_stats_gs = average_stats_gs.append(season_statistics_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##get the average stats per team for top 5 players based on the number of agmes started \n",
    "\n",
    "team_data = historical_team_data_top_5_advanced\n",
    "#relevant data for z scores are...\n",
    "team_data.columns #fg%, fga, 3p%, 3pa, 2pa, 2p%, fta, ft%, ord, drb, trb, ast, stl, blk, tov, pf, pts, efg%\n",
    "team_data = team_data[['season','fg%', 'fga', '3p%', '3pa', '2p%', '2pa', 'ft%', 'fta', 'orb', 'drb', 'trb', 'ast', 'stl',\n",
    "                      'blk', 'tov', 'pf', 'pts', 'efg%', 'age', 'per', '3par', 'ftr', 'orb%', 'drb%', 'trb%', 'ast%', \n",
    "                       'stl%', 'blk%', 'tov%','usg%', 'ows', 'dws', 'ws', 'ws/48', 'obpm', 'dbpm', 'bpm', 'vorp']]\n",
    "average_stats_advanced = pd.DataFrame()\n",
    "seasons = team_data['season'].unique()\n",
    "\n",
    "temp_data = team_data.drop('season', axis=1)\n",
    "for s in seasons:\n",
    "    season_data = temp_data[team_data['season'] == s]\n",
    "    season_statistics_top_5 = pd.DataFrame(columns = ['mean', 'sd'])\n",
    "    season_statistics_top_5['mean'] = season_data.mean()\n",
    "    season_statistics_top_5['sd'] = season_data.std()\n",
    "    season_statistics_top_5 = season_statistics_top_5.transpose()\n",
    "    season_statistics_top_5['season'] = s\n",
    "    average_stats_advanced = average_stats_advanced.append(season_statistics_top_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write data sets to csv\n",
    "historical_team_data.to_csv(path_or_buf=path + '/processed_data/historical_team_data.csv', index=False)\n",
    "historical_team_data_top_5.to_csv(path_or_buf=path + '/processed_data/historical_team_data_top_5.csv', index=False)\n",
    "historical_team_data_top_5_gs.to_csv(path_or_buf=path + '/processed_data/historical_team_data_top_5_gs.csv', index=False)\n",
    "historical_team_data_top_5_advanced.to_csv(path_or_buf=path + '/processed_data/historical_team_data_top_5_advanced.csv', index=False)\n",
    "pd_data.to_csv(path_or_buf=path + '/processed_data/player_data.csv', index=False)\n",
    "pd_pa_data.to_csv(path_or_buf=path + '/processed_data/player_advanced_data.csv', index=False)\n",
    "tms_data.to_csv(path_or_buf=path + '/processed_data/team_misc_stats_data.csv', index=False)\n",
    "season_average_data.to_csv(path_or_buf=path + '/processed_data/season_average_data.csv', index=False)\n",
    "playoff_data.to_csv(path_or_buf=path + '/processed_data/playoff_data.csv', index=False)\n",
    "player_data_sr.to_csv(path + \"/processed_data/player_data_single_record.csv\", index=False)\n",
    "player_data_sr_advanced.to_csv(path + '/processed_data/player_data_single_record_advanced.csv', index=False)\n",
    "average_stats.to_csv(path + '/processed_data/season_average_top_5_data.csv', index=True)\n",
    "average_stats_gs.to_csv(path + '/processed_data/season_average_top_5_gs_data.csv', index=True)\n",
    "average_stats_advanced.to_csv(path + '/processed_data/season_average_top_5_advanced_data.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
